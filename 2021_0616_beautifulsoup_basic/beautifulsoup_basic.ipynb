{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2095f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe8c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>test</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d9962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head></head><body><p>test</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c6c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <head>\\n </head>\\n <body>\\n  <p>\\n   test\\n  </p>\\n </body>\\n</html>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fd5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>나의 웹페이지</title></head>\n",
    "<p>test1</p>\n",
    "<p>test2</p>\n",
    "<p>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a527cf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <head>\\n  <title>\\n   나의 웹페이지\\n  </title>\\n </head>\\n <p>\\n  test1\\n </p>\\n <p>\\n  test2\\n </p>\\n <p>\\n  test3\\n </p>\\n</html>\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e936bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>test1</p>, <p>test2</p>, <p>test3</p>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\") # 리스트 형태로 찾은 값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034df28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test2</p>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")[1] # 인덱싱을 이용해서 원하는 값을 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fcc31b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test1</p>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\") # 첫번째 p 태그를 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77cafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e74d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>, <p class=\"class1\">test2</p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "soup.find_all(\"p\", \"class1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7883ea",
   "metadata": {},
   "source": [
    "실습\n",
    "1. p 요소 전부 가져오기\n",
    "2. span 요소 전부 가져오기\n",
    "3. head 요소 전부 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2131ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p 태그 요소: [<p align=\"left\" class=\"class1\">test3</p>, <p class=\"class1\">test2</p>, <p id=\"p1\">오늘의 주가지수 1500</p>, <p class=\"class4\">test3</p>]\n",
      "\n",
      "\n",
      "span 태그 요소: [<span class=\"class3\">span tag text</span>]\n",
      "\n",
      "\n",
      "head 태그 요소: <head><title> test site </title></head>\n"
     ]
    }
   ],
   "source": [
    "p_elements = soup.find_all(\"p\")\n",
    "span_element = soup.find_all(\"span\")\n",
    "head_element = soup.find(\"head\")\n",
    "\n",
    "print(\"p 태그 요소: {}\".format(p_elements))\n",
    "print('\\n')\n",
    "print(\"span 태그 요소: {}\".format(span_element))\n",
    "print('\\n')\n",
    "print(\"head 태그 요소: {}\".format(head_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd5769",
   "metadata": {},
   "source": [
    "### 주피터 노트북 단축기\n",
    "* ESC + M : 마크다운 셀 만들기\n",
    "* ESC + Y : 소스코드 실행 셀 만들기\n",
    "* ESC + A : 위에 셀 추가\n",
    "* ESC + B : 아래 셀 추가\n",
    "* ESC + X : 셀 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "607424be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"left\" class=\"class1\">test3</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<p id=\"p1\">오늘의 주가지수 1500</p>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 명으로 요소 가져오기\n",
    "print(soup.find(\"p\", class_=\"class1\"))\n",
    "\n",
    "# id 명으로 요소 가져오기\n",
    "print(soup.find(\"p\", id=\"p1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36d10cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<title>\\n test site\\n</title>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = soup.find(\"head\")\n",
    "print(type(data1))\n",
    "\n",
    "data1_title = data1.find(\"title\") # head 태그 안에 title 태그를 찾기\n",
    "print(type(data1_title))\n",
    "data1_title.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8022945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site </title>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"head\").find(\"title\") # .find() 매소드를 중복 사용해서 태그 속 태그를 찾는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe243fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p id=\"p1\">오늘의 주가지수 1500</p>\n",
      "<p class=\"class4\">test3</p>\n",
      "<span class=\"class3\">span tag text</span>\n",
      "</div>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "# div 2번째 요소 안의 p 태그 전체를 가져오기\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "second_div_tag = soup.find_all(\"div\")[1]\n",
    "print(second_div_tag)\n",
    "print(type(second_div_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8417e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"left\" class=\"class1\">test3</p>\n"
     ]
    }
   ],
   "source": [
    "# div 첫번째 요소의 첫번째 p 태그 요소 가져오기\n",
    "first_div_p_tag = soup.find_all(\"div\")[0]\n",
    "p_tag = first_div_p_tag(\"p\")[0]\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "981419bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <a href=\"https://www.google.com\">구글</a>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# a 태그의 모든 url을 가져오기\n",
    "a_tag = soup.find_all(\"a\")\n",
    "urls = []\n",
    "for i in range(len(a_tag)):\n",
    "    url = a_tag[i].attrs\n",
    "    urls.append(url['href'])\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b17c384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   test site\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <a href=\"https://www.google.com\">\n",
      "   구글\n",
      "  </a>\n",
      "  <div>\n",
      "   <p align=\"left\" class=\"class1\">\n",
      "    test3\n",
      "   </p>\n",
      "   <p class=\"class1\">\n",
      "    test2\n",
      "   </p>\n",
      "  </div>\n",
      "  <div>\n",
      "   <p id=\"p1\">\n",
      "    오늘의 주가지수 1500\n",
      "   </p>\n",
      "   <p class=\"class4\">\n",
      "    test3\n",
      "   </p>\n",
      "   <span class=\"class3\">\n",
      "    span tag text\n",
      "   </span>\n",
      "   <a href=\"https://www.naver.com/\">\n",
      "    네이버\n",
      "   </a>\n",
      "   <a href=\"https://www.daum.com/\">\n",
      "    다음\n",
      "   </a>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()) # 프린트 함수와 prettify() 함수를 같이 적용하면 정렬할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6075c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x26a15bee220>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1 = soup.find(\"div\")\n",
    "div1.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "225923d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list_iterator'>\n",
      "<span class=\"class3\">span tag text</span>\n"
     ]
    }
   ],
   "source": [
    "span = soup.find_all(\"div\")[1].children\n",
    "print(type(span))\n",
    "span = list(span)\n",
    "print(span[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27c83c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p align=\"left\" class=\"class1\">test3</p>\n",
      "<p class=\"class1\">test2</p>\n",
      "</div>\n",
      "<div>\n",
      "<p id=\"p1\">오늘의 주가지수 1500</p>\n",
      "<p class=\"class4\">test3</p>\n",
      "<span class=\"class3\">span tag text</span>\n",
      "<a href=\"https://www.naver.com/\">네이버</a>\n",
      "<a href=\"https://www.daum.com/\">다음</a>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = soup.findChildren(\"div\")\n",
    "for i in result:\n",
    "    print(i)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34ef92a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n",
      "test2\n",
      "오늘의 주가지수 1500\n",
      "test3\n"
     ]
    }
   ],
   "source": [
    "p_tag = soup.find_all(\"p\")\n",
    "for p in p_tag:\n",
    "    print(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e671a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'구글': 'https://www.google.com', '네이버': 'https://www.naver.com/', '다음': 'https://www.daum.com/'}\n"
     ]
    }
   ],
   "source": [
    "a_tag = soup.find_all(\"a\")\n",
    "urls = {}\n",
    "for url in a_tag:\n",
    "    url_name = url.string\n",
    "    urls[url_name] = url.attrs['href']\n",
    "    \n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "36fd7283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0                       0\n",
      "0   구글  https://www.google.com\n",
      "1  네이버  https://www.naver.com/\n",
      "2   다음   https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리의 키와 값을 이용해서 df에 적용할 수 있다.\n",
    "\n",
    "name = pd.DataFrame(urls.keys())\n",
    "link = pd.DataFrame(urls.values())\n",
    "df = pd.concat([name, link], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9d16a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글     https://www.google.com\n",
      "네이버    https://www.naver.com/\n",
      "다음      https://www.daum.com/\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dat1 = pd.Series(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee1d97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1.to_excel(\"회사명과 웹사이트.xlsx\", index=False)\n",
    "df.to_csv(\"회사명과 웹사이트.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bd315ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n",
      "['구글', '네이버', '다음']\n",
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "com = []\n",
    "urls = []\n",
    "list_a = soup.findAll(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text, one.get(\"href\"))\n",
    "    com.append(one.text)\n",
    "    urls.append(one.get('href'))\n",
    "print(com)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c70dd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"./01.html\" name=\"link_get\"> 01. 제목 가져오기(title) </a>\n",
      "<a href=\"./02.html\" name=\"text_get\"> 02. 텍스트 가져오기(p) </a>\n",
      "<a href=\"./03.html\" name=\"link_get\"> 03. 링크 가져오기(a) </a>\n",
      "<a href=\"https://pythonstart.github.io/web/04.html\"> 04. 이미지 가져오기(img) </a>\n",
      "<a href=\"./05.html\"> 05. 리스트 정보 가져오기(ul,ol) </a>\n",
      "<a href=\"./06.html\"> 06. id를 활용한 정보 획득 </a>\n",
      "<a href=\"./07.html\"> 07. class를 활용한 정보 획득 </a>\n",
      "<a href=\"./08.html\"> 08. 하나의 이미지 다운로드 </a>\n",
      "<a href=\"https://pythonstart.github.io/web/09.html\"> 09. 여러개의 이미지 다운로드 </a>\n",
      "<a href=\"./10.html\" id=\"rank\"> 10. 랭킹 정보 가져오기(웹 크롤링) </a>\n",
      "<a href=\"./nclass/index.html\"> Next Class --&gt;</a>\n",
      "<a href=\"https://www.naver.com/\">naver</a>\n"
     ]
    }
   ],
   "source": [
    "# https://ldjwj.github.io/00_PYTHON_LEVELUP_CLASS/web_class/index.html 이곳의 링크 가져오기\n",
    "\n",
    "url = 'https://ldjwj.github.io/00_PYTHON_LEVELUP_CLASS/web_class/index.html'\n",
    "page = urlopen(url)\n",
    "site = BeautifulSoup(page, 'html.parser')\n",
    "a_tag = site.find_all('a')\n",
    "for i in range(len(a_tag)):\n",
    "    print(a_tag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15402724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea1ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,277.91 999.59 436.73\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find(\"span\", id=\"KOSPI_now\").string\n",
    "kosdaq = soup.find(\"span\", id=\"KOSDAQ_now\").string\n",
    "kospi200 = soup.find(\"span\", id=\"KPI200_now\").string\n",
    "\n",
    "print(kospi, kosdaq, kospi200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fab49fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.NAVER394,000상승', '2.카카오143,500하락', '3.삼성전자81,700상승', '4.대원전선3,605상승', '5.두산중공업24,700상승', '6.가비아19,100상한가', '7.HMM45,550상승', '8.쌍방울1,270하락', '9.서울식품455상승', '10.대한전선3,310상승']\n"
     ]
    }
   ],
   "source": [
    "popular_tag = soup.find(\"div\", class_=\"rgt\")\n",
    "names = popular_tag.find(\"ul\").find_all(\"li\")\n",
    "popular_stocks = []\n",
    "\n",
    "for name in names:\n",
    "    popular_stocks.append(name.text)\n",
    "print(popular_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "865fd3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a><span class=\"up\">394,000</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_stock = soup.find(\"ul\", id=\"popularItemList\")\n",
    "stock_all = search_stock.find_all(\"li\")\n",
    "stock_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "faf76835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVER\n",
      "394,000\n"
     ]
    }
   ],
   "source": [
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2314d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVER\n",
      "394,000\n",
      "카카오\n",
      "143,500\n",
      "삼성전자\n",
      "81,700\n",
      "대원전선\n",
      "3,605\n",
      "두산중공업\n",
      "24,700\n",
      "가비아\n",
      "19,100\n",
      "HMM\n",
      "45,550\n",
      "쌍방울\n",
      "1,270\n",
      "서울식품\n",
      "455\n",
      "대한전선\n",
      "3,310\n"
     ]
    }
   ],
   "source": [
    "com_all = []\n",
    "price_all = []\n",
    "\n",
    "for one in stock_all:\n",
    "    com_one = one.find(\"a\").text\n",
    "    price_one = one.find(\"span\").text\n",
    "    print(com_one)\n",
    "    print(price_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e99e70a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=005930\" onclick=\"clickcr(this,'boa.list','005930','1',event)\">삼성전자</a><span class=\"up\">81,600</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#주식 인기 검색 종목 가지고 오기\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "popular_stocks = soup.find(\"ul\", id='popularItemList')\n",
    "popular_stocks.find(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "573491f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "삼성전자\n",
      "81,600\n",
      "상승\n",
      "005930\n"
     ]
    }
   ],
   "source": [
    "# 네이버 주식 웹페이지에서 하나의 Tag에서 원하는 '정보'만 추출 테스트 및 확인\n",
    "\n",
    "print(stocks_info[0].find('em').text) # 순위\n",
    "print(stocks_info[0].find('a').text) # 종목 이름\n",
    "print(stocks_info[0].find('span').text) # 가격\n",
    "print(stocks_info[0].find('span', class_='blind').string) # 상승 혹은 하강\n",
    "print(stocks_info[0].find('a').attrs['onclick'].split(',')[2].strip(\"''\")) # 종목 코드명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "97677b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>종목명</th>\n",
       "      <th>가격</th>\n",
       "      <th>변동</th>\n",
       "      <th>종목코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>쌍방울</td>\n",
       "      <td>1,050</td>\n",
       "      <td>하락</td>\n",
       "      <td>102280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>81,800</td>\n",
       "      <td>상승</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>한전산업</td>\n",
       "      <td>11,100</td>\n",
       "      <td>상한가</td>\n",
       "      <td>130660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>카카오</td>\n",
       "      <td>143,000</td>\n",
       "      <td>하락</td>\n",
       "      <td>035720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>두산중공업</td>\n",
       "      <td>24,450</td>\n",
       "      <td>상승</td>\n",
       "      <td>034020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>HMM</td>\n",
       "      <td>45,050</td>\n",
       "      <td>상승</td>\n",
       "      <td>011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NAVER</td>\n",
       "      <td>391,000</td>\n",
       "      <td>상승</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>가비아</td>\n",
       "      <td>19,100</td>\n",
       "      <td>상한가</td>\n",
       "      <td>079940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>대한전선</td>\n",
       "      <td>3,275</td>\n",
       "      <td>상승</td>\n",
       "      <td>001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>대원전선</td>\n",
       "      <td>3,555</td>\n",
       "      <td>상승</td>\n",
       "      <td>006340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위    종목명       가격   변동    종목코드\n",
       "0   1    쌍방울    1,050   하락  102280\n",
       "1   2   삼성전자   81,800   상승  005930\n",
       "2   3   한전산업   11,100  상한가  130660\n",
       "3   4    카카오  143,000   하락  035720\n",
       "4   5  두산중공업   24,450   상승  034020\n",
       "5   6    HMM   45,050   상승  011200\n",
       "6   7  NAVER  391,000   상승  035420\n",
       "7   8    가비아   19,100  상한가  079940\n",
       "8   9   대한전선    3,275   상승  001440\n",
       "9  10   대원전선    3,555   상승  006340"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주식 인기 검색 종목 가지고 오기\n",
    "# 정보 추출을 위한 로직을 반복문에 적용해서 주식 인기 검색 종목 정보 크롤링\n",
    "\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "popular_stocks = soup.find(\"ul\", id='popularItemList')\n",
    "popular_stocks.find(\"li\")\n",
    "\n",
    "all_info = []\n",
    "stocks_info = popular_stocks.find_all(\"li\")\n",
    "\n",
    "for stock in stocks_info:\n",
    "    dictionary = {}\n",
    "    dictionary['순위'] = stock.find('em').text[0:-1]\n",
    "    dictionary['종목명'] = stock.find('a').text\n",
    "    dictionary['가격'] = stock.find('span').text\n",
    "    dictionary['변동'] = stock.find('span', class_='blind').string\n",
    "    dictionary['종목코드'] = stock.find('a').attrs['onclick'].split(',')[2].strip(\"''\")\n",
    "    all_info.append(dictionary)\n",
    "\n",
    "popular_df = pd.DataFrame(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba9240e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><a href=\"/world/sise.nhn?symbol=DJI@DJI&amp;fdtc=0\" onclick=\"clickcr(this,'wst.dow','','',event)\">다우산업</a><span class=\"dn\">34,299.33</span><em class=\"bu_p bu_pdn\"><span class=\"blind\">하락</span></em></li>\n"
     ]
    }
   ],
   "source": [
    "# 해외지수 가지고 오기\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "foreign_index = soup.find(\"ul\", class_='lst_major')\n",
    "foreign_index_all = foreign_index.find_all('li')\n",
    "print(foreign_index_all[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b206603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다우산업\n",
      "34,299.33\n",
      "하락\n",
      "'wst.dow'\n"
     ]
    }
   ],
   "source": [
    "print(foreign_index_all[0].find('a').text) # name\n",
    "print(foreign_index_all[0].find('span').string) # price\n",
    "print(foreign_index_all[0].find('span', class_='blind').string) # 변동\n",
    "print(foreign_index_all[0].find('a').attrs['onclick'].split(',')[1]) # 지수코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2a295ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해외지수 정보 가져오기. pd.concat() 매소드로 시리즈 객채들을 합쳐서 결과물 만들기\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "changes = []\n",
    "codes = []\n",
    "\n",
    "for index in foreign_index_all:\n",
    "    names.append(index.find('a').text)\n",
    "    prices.append(index.find('span').string)\n",
    "    changes.append(index.find('span', class_='blind').string)\n",
    "    codes.append(index.find('a').attrs['onclick'].split(',')[1].strip(\"''\"))\n",
    "\n",
    "names = pd.Series(names)\n",
    "prices = pd.Series(prices)\n",
    "changes = pd.Series(changes)\n",
    "codes = pd.Series(codes)\n",
    "\n",
    "columns_name = ['해외지수 이름', '가격', '변동', '코드']\n",
    "final_index = pd.concat([names, prices, changes, codes], axis=1)\n",
    "\n",
    "final_index.to_excel('해외지수 종목.xlsx')\n",
    "final_index.to_csv('해외지수 종목.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6ecbe86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해외지수 정보 가져오기. dictionary에 리스트로 담은 정보를 df로  변환하기 (딕셔너리 키값이 인덱스가 됨)\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "changes = []\n",
    "codes = []\n",
    "\n",
    "for index in foreign_index_all:\n",
    "    names.append(index.find('a').text)\n",
    "    prices.append(index.find('span').string)\n",
    "    changes.append(index.find('span', class_='blind').string)\n",
    "    codes.append(index.find('a').attrs['onclick'].split(',')[1].strip(\"''\"))\n",
    "\n",
    "index_dictionary = {}\n",
    "index_dictionary['해외지수 이름'] = names\n",
    "index_dictionary['수치'] = prices\n",
    "index_dictionary['변동'] = changes\n",
    "index_dictionary['코드'] = codes\n",
    "\n",
    "outcome = pd.DataFrame(index_dictionary)\n",
    "outcome.to_excel('해외지수 정보.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
